{
  "_args": [
    [
      {
        "raw": "async-kit",
        "scope": null,
        "escapedName": "async-kit",
        "name": "async-kit",
        "rawSpec": "",
        "spec": "latest",
        "type": "tag"
      },
      "/Users/panagiotis/Desktop/nextcommerce database migration script"
    ]
  ],
  "_from": "async-kit@latest",
  "_id": "async-kit@2.2.3",
  "_inCache": true,
  "_location": "/async-kit",
  "_nodeVersion": "6.9.1",
  "_npmOperationalInternal": {
    "host": "packages-12-west.internal.npmjs.com",
    "tmp": "tmp/async-kit-2.2.3.tgz_1479474575094_0.9020743810106069"
  },
  "_npmUser": {
    "name": "cronvel",
    "email": "cedric.ronvel@gmail.com"
  },
  "_npmVersion": "3.10.8",
  "_phantomChildren": {},
  "_requested": {
    "raw": "async-kit",
    "scope": null,
    "escapedName": "async-kit",
    "name": "async-kit",
    "rawSpec": "",
    "spec": "latest",
    "type": "tag"
  },
  "_requiredBy": [
    "#USER"
  ],
  "_resolved": "http://registry.npmjs.org/async-kit/-/async-kit-2.2.3.tgz",
  "_shasum": "264751a279ddc5f59b419638b805ae2c49858fb7",
  "_shrinkwrap": null,
  "_spec": "async-kit",
  "_where": "/Users/panagiotis/Desktop/nextcommerce database migration script",
  "author": {
    "name": "Cédric Ronvel"
  },
  "bugs": {
    "url": "https://github.com/cronvel/async-kit/issues"
  },
  "copyright": {
    "title": "Async Kit",
    "years": [
      2014,
      2016
    ],
    "owner": "Cédric Ronvel"
  },
  "dependencies": {
    "nextgen-events": "^0.9.0",
    "tree-kit": "^0.5.26"
  },
  "description": "A simple and powerful async abstraction lib for easily writing Node.js code.",
  "devDependencies": {
    "browserify": "^13.1.0",
    "expect.js": "^0.3.1",
    "jshint": "^2.9.2",
    "mocha": "^2.5.3",
    "uglify-js": "^2.7.0"
  },
  "directories": {
    "test": "test"
  },
  "dist": {
    "shasum": "264751a279ddc5f59b419638b805ae2c49858fb7",
    "tarball": "https://registry.npmjs.org/async-kit/-/async-kit-2.2.3.tgz"
  },
  "gitHead": "43089e0d6aa9030462c2aed59ed80995ee9e82bd",
  "homepage": "https://github.com/cronvel/async-kit#readme",
  "keywords": [
    "async",
    "asynchronous",
    "flow",
    "jobs",
    "series",
    "parallel",
    "conditionnal",
    "if",
    "then",
    "else",
    "catch",
    "finally",
    "waterfall",
    "race",
    "foreach",
    "map",
    "reduce",
    "while",
    "loop",
    "callback",
    "retry",
    "exit",
    "events",
    "scheduler",
    "progress",
    "csk",
    "easy"
  ],
  "license": "MIT",
  "main": "lib/async.js",
  "maintainers": [
    {
      "name": "cronvel",
      "email": "cedric.ronvel@gmail.com"
    }
  ],
  "name": "async-kit",
  "optionalDependencies": {},
  "readme": "\n# Async Kit\n\nA simple and powerful async abstraction layer lib to easily write Node.js code.\n\n* License: MIT\n* Platform: Node.js and modern browsers\n\nWhile inspired in some way by [caolan/async](https://github.com/caolan/async), Async Kit uses a completely different approach.\n\nRather than having a whole bunch of specific functions, this lib provides a generic way to solve async code flow.\nSo anything that can be done by caolan/async lib can be converted to Async Kit, but the reverse is not always true.\n\nUsing natural syntax really easy to become familiar with, you will be able to code great things effortlessly, \nwithout cumbersome callback hell, and without coding again and again the same async pattern and logic.\n\nPlease read [this doc on Github](https://github.com/cronvel/async-kit.git), npmjs.org truncate it.\n\n\n\n# Quick example\n\n```js\nasync.series( [\n\tfunction( callback ) {\n\t\tletsConnectToDatabase( callback ) ;\n\t} ,\n\tfunction( callback ) {\n\t\tletsQueryTheDatabase( callback ) ;\n\t} ,\n\tfunction( callback ) {\n\t\tdoMoreQueries( callback ) ;\n\t}\n] )\n.exec( function( error , results ) {\n\tif ( error ) { console.log( 'Doh!' ) ; }\n\telse { console.log( 'Yay! Done!' ) ; }\n} ) ;\n```\n\nThis small example prepares an async job's list and executes it. \n\nAll jobs are executed in series, one after one.\n\nEach callback works the Node.js way, the first argument is always the *error* argument.\n\nIf one job fails (ie it triggers its callback with an error or any *truthy* value), all remaining jobs are skipped \nand the `exec()`'s callback is instantly called with that error.\n\nWhen every jobs are finished, the `exec()`'s callback is called, the *results* argument contains an array of the *arguments* passed by each job to its callback.\n\n\n\n# Features\n\n### Code flow\n\n* [Series](#ref.async.series)\n* [Parallel](#ref.async.parallel)\n* [Race (parallel, stop when the first job finish without error)](#ref.async.race)\n* [Waterfall (series, each job transmits its results to the next)](#ref.async.waterfall)\n* [While loop](#ref.async.while.do), [do while loop](#ref.async.do.while)\n* [Foreach](#ref.async.foreach)\n* [Map](#ref.async.map)\n* [Reduce](#ref.async.reduce)\n* [Async if](#ref.async.if.and)/[and](#ref.async.and)\n* [Async if](#ref.async.if.or)/[or](#ref.async.or)\n* [Nested async if](#ref.nested)\n\n\n\n### Modifier\n\n* [Set the parallel limit](#ref.async.Plan.parallel)\n* [While conditions](#ref.async.Plan.while)\n* [Repeat jobs a fixed amount of time](#ref.async.Plan.repeat)\n* [Iterator](#ref.async.Plan.iterator)\n* [Timeout for jobs (avoid pending jobs troubles)](#ref.async.Plan.timeout)\n* [Retry jobs on error (useful for managing outgoing connection for example)](#ref.async.Plan.retry)\n* [Async/sync job's scheduling controle (turn sync jobs into async, change the *nice* value of the job's scheduler)](#ref.async.Plan.nice)\n* [Continue on error or not](#ref.async.Plan.fatal)\n* [Transmission of all jobs' results or only results of the last job](#ref.async.Plan.lastJobOnly)\n* [Then callback, if successful](#ref.callback.thenCallback)\n* [Else callback, for *async if*](#ref.callback.elseCallback)\n* [Catch callback, if an error occurs](#ref.callback.catchCallback)\n* [Finally callback, always executed](#ref.callback.finallyCallback)\n* [Define input arguments to invoke `.exec()` with, that are transmitted to jobs](#ref.async.Plan.execMapping)\n* [Export a plan as a simple function](#ref.async.Plan.export)\n\n\n\n### Misc\n\n* [Async exit](#ref.async.exit)\n* [Safe Timeout](#ref.async.setSafeTimeout)\n\n\n\n# Install\n\nUse Node Package Manager:\n\n    npm install async-kit\n\n\n\n# Plan stage & exec stage concept\n\nThis is an important concept to understand when using this lib: there are two stages to perform an async flow.\n\nIn the first stage, you define the plan.\nAll plan definition returns an `async.Plan` object.\n\nThen you can `.exec()` your plan as many time as you want. All the *exec* method family returns an *execContext* object.\nThe first time an `async.Plan` is `.exec()`, it becomes locked forever: you cannot modify it anymore.\n\nThe example above becomes:\n\n```js\n// Plan stage, jobs' definition\nvar plan = async.series( [\n\tfunction( callback ) {\n\t\tletsConnectToDatabase( callback ) ;\n\t} ,\n\tfunction( callback ) {\n\t\tletsQueryTheDatabase( callback ) ;\n\t} ,\n\tfunction( callback ) {\n\t\tdoMoreQueries( callback ) ;\n\t}\n] ) ;\n\n// Change the plan, each job should terminate within 200ms\nplan.timeout( 200 ) ;\n\n// Exec stage\nplan.exec( function( error , results ) {\n\tif ( error ) { console.log( 'Doh!' ) ; }\n\telse { console.log( 'Yay! Done!' ) ; }\n} ) ;\n\nplan.exec( function( error , results ) {\n\tif ( error ) { console.log( 'Doh x2!' ) ; }\n\telse { console.log( 'Yay! Again!' ) ; }\n} ) ;\n\n// No effect! Plan cannot be modified anymore!\nplan.timeout( 200 ) ;\n```\n\n\n\n# Callbacks & the error argument\n\nIn most case, callbacks work in the Node.js fashion, except explicitly expressed otherwise.\nThe callback should always be called with arguments in this order:\n\n```js\ncallback( [error] , [argument1] , [argument2] , ... ) ;\n```\n\nThat's it: the first argument, if present, is always assumed to be the error argument.\n\nAsync Kit will assume that something is wrong with a job if it get **ANY** truthy value as the error argument,\nweither it is an instanceof of *Error*, *true*, *'my error message'*, or any expression evaluated to true.\nIf you are unsure what are *truthy* and *falsy* values, \n[check this out](http://docs.nodejitsu.com/articles/javascript-conventions/what-are-truthy-and-falsy-values).\n\n\n\n# Common use cases\n\n### Perform asynchronous database queries\n\n**Use case**: this is probably the most common use case for any website, we have to perform\na series of async query, each query should be sent after the previous one succeed.\n\n```js\nasync.waterfall( [\n\tfunction getUserByLoginAndPassword( login , password , callback ) {\n\t\tdbUserCollection.findOne( { login: login, password: password } , callback ) ;\n\t} ,\n\t\n\tfunction getUserPhoto( userDocument , callback ) {\n\t\tdbPhotoCollection.findOne( { _id: userDocument.photoID } , callback ) ;\n\t}\n] )\n.timeout( 200 )\n.then( function( photoDocument ) {\n\thttpResponse.writeHead( 200 , { 'Content-Type' : 'image/png' } ) ;\n\thttpResponse.write( photoDocument.rawData ) ;\n\thttpResponse.end() ;\n} )\n.catch( function( error ) {\n\thttpResponse.writeHead( 404 , { 'Content-Type' : 'text/plain' } ) ;\n\thttpResponse.write( '404 - Not found.' ) ;\n\thttpResponse.end() ;\n} )\n.execArgs( 'john@example.com' , 'god' ) ;\n```\n\n**Explanation**: \n- *async.waterfall()* declare a job list in *waterfall* mode, when one job finish, it pass arguments to the next job\n- *dbUserCollection.findOne()* & *dbPhotoCollection.findOne* are some kind of MongoDB pseudo-code,\n  they return a document from the collection\n- *getUserPhoto()* receive a document of the authenticated user\n- *timeout( 200 )* assume each job should perform within 200ms, if a job hit the time limit, it works as if\n  the job itself passed an error to its callback, here *.catch()* is immediately triggered if it happens\n- *.then()* declare a *then callback* in the *Plan* itself, it will be triggered if we manage to authenticate the user\n  and get its photo\n- *.catch()* declare a *catch callback* in the *Plan* itself, it will be triggered if a job fails\n- *.execArgs()* is used when you do not want to pass callback to `.exec()`-like function, since by default\n  `.exec()` assume than its last argument is the *finally callback*, so since we are in *waterfall* mode, every\n  arguments passed to *execArgs()* are passed only to the first job\n\nYou can chain as many queries as you want, without burying them deeper and deeper in nested callback hell.\n\n\n\n### Get informations on various mirror URL as fast as possible\n\n**Use case**: we want to get some contents (JSON, HTML, RSS, etc), many mirrors are available \nbut we don't want to try them one at a time, we want to try them all at once and finish \nas soon as possible, when the first non-error response is received.\n\n```js\nasync.race( [ url1 , url2 , url3 , url4 ] )\n.using( function( url , callback ) {\n\tgetContentFromUrl( url , callback ) ;\n} )\n.then( function( contents ) {\n\tdoSomethingWithContent( contents ) ;\n} )\n.catch( function( error ) {\n\tconsole.log( \"Cannot get contents from any mirror\" ) ;\n} )\n.exec() ;\n```\n\n**Explanation**: \n- *async.race()* declare a job list of four racing elements to process, in parallel mode, \n  triggering callback when the first non-error job finished\n- *.using()* declare the function used to process them (iterator-like, if it means anything in a parallel context)\n- *getContentFromUrl()* is a user-defined function that take an URL and a callback, try to get contents from\n  that URL and call its callback the Node.js way: `callback( error , contents )`\n- *.then()* declare a *then callback* in the *Plan* itself, it will be triggered if we get what we want\n- *doSomethingWithContent()* is a user-defined function, that process the contents\n- *.catch()* declare a *catch callback* in the *Plan* itself, it will be triggered if **ALL** jobs have failed\n- here *.exec()* is called without argument, so it executes the *Plan* with no callback of its own: \n  if we do not want to re-use the *Plan* it improves readability to use *.then()* and *.catch()* directly\n  in the *Plan* definition part.\n\n\n\n### Async foreach\n\n**Use case**: we have an array, we want to iterate it but there are some async code in the iterator, \nand we really want that each element to be processed one at a time. The native javascript *myArray.forEach()*\nwould parallelize the async part even if we don't want.\n\n```js\nasync.foreach( myArray , function( element , callback ) {\n\tdoSomethingAsyncWithElement( element , callback ) ;\n} )\n.exec( function( error ) {\n\tconsole.log( \"Finished!\" ) ;\n} ) ;\n```\n\n**Explanation**: \n- *async.foreach( myArray , function )* define a job list with myArray, and specify an iterator function\n- *doSomethingAsyncWithElement()* should trigger its callback when the job is finished\n- When all element have been processed, the `.exec()`'s callback is triggered, as usual\n\nYou can as well add a ```.parallel()``` before `.exec()`, you still have the advantage versus native forEach()\nof having a general callback triggered when everything is asynchronously done.\n\n\t\n\n# Reference\n\n* [*Do* family factories](#ref.do.factories)\n\t* [async.do()](#ref.async.do)\n\t* [async.series()](#ref.async.series)\n\t* [async.parallel()](#ref.async.parallel)\n\t* [async.race()](#ref.async.race)\n\t* [async.waterfall()](#ref.async.waterfall)\n\t* [async.foreach()](#ref.async.foreach)\n\t* [async.map()](#ref.async.map)\n\t* [async.reduce()](#ref.async.reduce)\n\t* [async.while().do()](#ref.async.while.do)\n\t* [async.do().while()](#ref.async.do.while)\n* [*Conditional* family factories](#ref.conditional.factories)\n\t* [async.and()](#ref.async.and)\n\t* [async.or()](#ref.async.or)\n\t* [async.if.and()](#ref.async.if.and)\n\t* [async.if.or()](#ref.async.if.or)\n\t* [Nested condition()](#ref.nested)\n* [Class async.Plan](#ref.async.Plan)\n\t* [.do()](#ref.async.Plan.do)\n\t* [.parallel()](#ref.async.Plan.parallel)\n\t* [.race()](#ref.async.Plan.race)\n\t* [.waterfall()](#ref.async.Plan.waterfall)\n\t* [.while()](#ref.async.Plan.while)\n\t* [.repeat()](#ref.async.Plan.repeat)\n\t* [.fatal()](#ref.async.Plan.fatal)\n\t* [.boolean()](#ref.async.Plan.boolean)\n\t* [.transmitError()](#ref.async.Plan.transmitError)\n\t* [.timeout()](#ref.async.Plan.timeout)\n\t* [.retry()](#ref.async.Plan.retry)\n\t* [Mixing .timeout() & .retry()](#ref.mixing.timeout.retry)\n\t* [.lastJobOnly()](#ref.async.Plan.lastJobOnly)\n\t* [.mapping1to1()](#ref.async.Plan.mapping1to1)\n\t* [.using()](#ref.async.Plan.using)\n\t* [.iterator()](#ref.async.Plan.iterator)\n\t* [.aggregator()](#ref.async.Plan.aggregator)\n\t* [.nice()](#ref.async.Plan.nice)\n\t* [.then()](#ref.async.Plan.then)\n\t* [.else()](#ref.async.Plan.else)\n\t* [.catch()](#ref.async.Plan.catch)\n\t* [.finally()](#ref.async.Plan.finally)\n\t* [.clone()](#ref.async.Plan.clone)\n\t* [.export()](#ref.async.Plan.export)\n\t* [.exec()](#ref.async.Plan.exec)\n\t* [.execFinally()](#ref.async.Plan.execFinally)\n\t* [.execThenCatch()](#ref.async.Plan.execThenCatch)\n\t* [.execThenElse()](#ref.async.Plan.execThenElse)\n\t* [.execThenElseCatch()](#ref.async.Plan.execThenElseCatch)\n\t* [.execArgs()](#ref.async.Plan.execArgs)\n\t* [.execMapping()](#ref.async.Plan.execMapping)\n\t* [.execKV()](#ref.async.Plan.execKV)\n* [Callback types](#ref.callback)\n\t* [thenCallback()](#ref.callback.thenCallback)\n\t* [elseCallback()](#ref.callback.elseCallback)\n\t* [catchCallback()](#ref.callback.catchCallback)\n\t* [finallyCallback()](#ref.callback.finallyCallback)\n\t* [whileCallback()](#ref.callback.whileCallback)\n* [Class async.ExecContext](#ref.async.ExecContext)\n\t* [.getJobsStatus()](#ref.async.ExecContext.getJobsStatus)\n\t* [Event: 'progress'](#ref.async.ExecContext.event.progress)\n\t* [Event: 'resolved'](#ref.async.ExecContext.event.resolved)\n\t* [Event: 'finish'](#ref.async.ExecContext.event.finish)\n* [Class async.JobContext](#ref.async.JobContext)\n\t* [.execContext](#ref.async.JobContext.execContext)\n\t* [.abort()](#ref.async.JobContext.abort)\n\t* [Event: 'timeout'](#ref.async.JobContext.event.finish)\n* [Misc utilities](#ref.misc)\n\t* [async.exit](#ref.async.exit)\n\t* [async.setSafeTimeout](#ref.async.setSafeTimeout)\n\t* [async.clearSafeTimeout](#ref.async.clearSafeTimeout)\n\n\n\n\n\n<a name=\"ref.do.factories\"></a>\n## *Do* family factories\n\nThey create `async.Plan` object and set up the job's list.\n\nNote that an `async.Plan` do not perform anything until its `.exec()` method is called (see Class async.Plan for details).\nThe following informations describe what happend when the plan is executed.\n\nBy default, jobs are processed one at a time.\n\nIf an error occurs, no new jobs will be processed.\n\nJobs should trigger their callback the Node.js way: `callback( error , [arg1] , [arg2] , ... )`.\n\nThe `finally` callbacks (see below) are triggered when the first error occurs or when all jobs are done.\n\nNote: **all factories below are described relative to this point of reference.**\nOnly differences will be reported.\n\n\n\n<a name=\"ref.async.do\"></a>\n### async.do( jobsList )\n\n* jobsList `Array` or `Object`\n\nThis is the most generic factory, with default behaviour, with no further limitation.\n\nSee *Do* family factories above.\n\n\n\n<a name=\"ref.async.series\"></a>\n### async.series( jobsList )\n\n* jobsList `Array` or `Object`\n\nSet up a job's list to be processed in series.\n\n**Calling `.parallel()` on it has no effect, it will process jobs one at a time anyway.**\n\n\n\n<a name=\"ref.async.parallel\"></a>\n### async.parallel( jobsList )\n\n* jobsList `Array` or `Object`\n\nSet up a job's list to be processed in parallel.\nThe parallel limit is set to `Infinity` by default.\n\n\n\n<a name=\"ref.async.race\"></a>\n### async.race( jobsList )\n\n* jobsList `Array` or `Object`\n\nSet up a job's list to be processed in parallel.\nThe parallel limit is set to `Infinity` by default.\n\nThe whole jobs processing aborts when the first job finish without error.\n\nJobs processing continues on error.\n\nNote that `async.race( jobsList )` is the same than `async.parallel( jobsList ).fatal( false ).race()`.\n\n\n\n<a name=\"ref.async.waterfall\"></a>\n### async.waterfall( jobsList )\n\n* jobsList `Array` or `Object`\n\nSet up a job's list to be processed in series, in waterfall mode.\n\nEach job is called with the previous job output as arguments.\n\nBy default, the `.exec()` method accept arguments to pass to the first job.\n\nBy default, the *error* argument is not transmitted, see [.transmitError()](#ref.async.Plan.transmitError) for details.\n\nOnly the last job pass its result to [*finallyCallback*](#ref.callback.finallyCallback), [*thenCallback*](#ref.callback.thenCallback) etc...\nSee [.lastJobOnly()](#ref.async.Plan.lastJobOnly) for details.\n\n**Calling `.parallel()` on it has no effect, it will process jobs one at a time anyway.**\n\nExample:\n```js\nasync.waterfall( [\n\tfunction( str , callback ) {\n\t\t// str equals 'oh', passed by .exec()'s first argument\n\t\tcallback( null , str + ' my' ) ;\n\t\t// null is the error argument, it is not transmitted to the next job by default\n\t} ,\n\tfunction( str , callback ) {\n\t\t// str equals 'oh my', passed by the previous job\n\t\tcallback( null , str + ' wonderful' ) ;\n\t\t// null is the error argument, it is not transmitted to the next job by default\n\t} ,\n\tfunction( str , callback ) {\n\t\t// str equals 'oh my wonderful', passed by the previous job\n\t\tcallback( null , str + ' result' ) ;\n\t}\n] )\n.exec( 'oh' , function( error , results ) {\n\t// output 'oh my wonderful result'\n\tconsole.log( results ) ;\n} ) ;\n```\n\nAny number of arguments can be used.\nThe previous example can become something like this:\n\n```js\nasync.waterfall( [\n\tfunction( str1 , str2 , str3 , callback ) {\n\t\t// str1 equals 'Hello', passed by .exec()'s first argument\n\t\t// str2 equals 'world', passed by .exec()'s second argument\n\t\t// str3 equals 'this', passed by .exec()'s third argument\n\t\tcallback( null , str1 + ' ' + str2 + ' ' + str3 + ' is' ) ;\n\t} ,\n\tfunction( str , callback ) {\n\t\t// str equals 'Hello world, this is', passed by the previous job\n\t\tcallback( null , str + ' my' , 'wonderful' ) ;\n\t} ,\n\tfunction( str1 , str2 , callback ) {\n\t\t// str1 equals 'Hello world, this is my', passed by the previous job\n\t\t// str2 equals 'wonderful', passed by the previous job\n\t\tcallback( null , str1 + ' ' + str2 + ' result' ) ;\n\t}\n] )\n.exec( 'Hello' , 'world,' , 'this' , function( error , results ) {\n\t// output 'Hello world, this is my wonderful result'\n\tconsole.log( results ) ;\n} ) ;\n```\n\n\n\n<a name=\"ref.async.foreach\"></a>\n### async.foreach( container , iterator )\n\n* container `Array` or `Object` to iterate\n* iterator `Function( element , [key] , [container] , callback )` where:\n\t* element `mixed` the current array element or object's property value\n\t* key `Number` or `String` the current key (index for array, property name for object)\n\t* container `Array` or `Object`, this is the original container\n\t* callback `Function( error , [arg1] , [arg2] , ... )` a node-style callback to trigger on completion\n\nIt performs an async foreach, iterating *container*, using *iterator*. \n\nDepending on `iterator.length` (the number of arguments the user-provided function accept), the arguments passed to *iterator*\nwill be `( element , callback )`, `( element , key , callback )`, or `( element , key , container , callback )`\nwhere *element* is the current element, *key* is the current key (the current index if *container* is an Array,\nor the current property's name if *container* is an object), *container* is the original container,\nand *callback* is the completion's callback.\n\nBy default, `element`s are performed one at a time, in **series**.\n\nIf the *iterator* fails for one element, it will continue processing others elements anyway.\n\nNote that `async.foreach( container , iterator )` is equal to `async.do( container ).iterator( iterator )`.\n\nExample:\n```js\nvar myArray = [ 'one' , 'two' , 'three' ] ;\n\nasync.foreach( myArray , function( element , callback ) {\n\t// Called three time, with element's value: 'one', then 'two', then 'three'\n\tdoSomethingAsyncWithElement( element , callback ) ;\n} )\n.exec( function( error , results ) {\n\tthingsToDoWhenFinished() ;\n} ) ;\n```\n\n\n\n<a name=\"ref.async.map\"></a>\n### async.map( container , iterator )\n\n* container `Array` or `Object` to iterate\n* iterator `Function( element , [key] , [container] , callback )` where:\n\t* element `mixed` the current array element or object's property value\n\t* key `Number` or `String` the current key (index for array, property name for object)\n\t* container `Array` or `Object`, this is the original container\n\t* callback `Function( error , [arg1] , [arg2] , ... )` a node-style callback to trigger on completion\n\nIt performs an async map, iterating *container*, using *iterator*.\nAn async map takes an array and produces a new array, each value in the input array is mapped into the output array, preserving indexes.\nIf an object is provided instead of an array, it produces a new object, preserving keys.\n\nDepending on `iterator.length` (the number of arguments the user-provided function accept), the arguments passed to *iterator*\nwill be `( element , callback )`, `( element , key , callback )`, or `( element , key , container , callback )`\nwhere *element* is the current element, *key* is the current key (the current index if *container* is an Array,\nor the current property's name if *container* is an object), *container* is the original container,\nand *callback* is the completion's callback.\n\nBy default, `element`s are performed in **parallel** mode.\n\nIf the *iterator* fails for one element, it will continue processing others elements anyway.\n\nThe *results* (see example below) directly map the *container*, like [`.mapping1to1()`](#ref.async.Plan.mapping1to1) do.\n\nNote that `async.map( container , iterator )` is equal to `async.do( container ).iterator( iterator ).mapping1to1()`.\n\nExample:\n```js\nvar myArray = [ 'my' , 'wonderful' , 'result' ] ;\n\nasync.map( myArray , function( element , callback ) {\n\t\n\tsetTimeout( function() {\n\t\tcallback( null , element.length ) ;\n\t} , 0 ) ;\n} )\n.exec( function( error , results ) {\n\t// we expect results to be equal to [ 2, 9, 6 ]\n\texpect( results ).to.be.eql( [ 2, 9, 6 ] ) ;\n} ) ;\n```\n\n\n\n<a name=\"ref.async.reduce\"></a>\n### async.reduce( container , [aggregatedValue] , iterator )\n\n* container `Array` or `Object` to iterate\n* aggregatedValue `mixed` the initial default reduced (aggregated) value\n* iterator `Function( aggregatedValue , element , [key] , [container] , callback )` where:\n\t* aggregatedValue `mixed` the current reduced value\n\t* element `mixed` the current array element or object's property value\n\t* key `Number` or `String` the current key (index for array, property name for object)\n\t* container `Array` or `Object`, this is the original container\n\t* callback `Function( error , newAggregatedValue , [arg1] , [arg2] , ... )` a node-style callback to trigger on completion, where:\n\t\t* newAggregatedValue `mixed` is the new reduced value that will be passed to the next iteration\n\nIt performs an async reduce, iterating *container*, using *iterator*.\nAn async reduce takes an array (or an object), and iterate it to produce a single reduced value (though actually this single *value*\ncan be anything we like, even an array or object).\n\nDepending on `iterator.length` (the number of arguments the user-provided function accept), the arguments passed to *iterator*\nwill be `( aggregatedValue , element , callback )`, `( aggregatedValue , element , key , callback )`,\nor `( aggregatedValue , element , key , container , callback )`, where *aggregatedValue* is the current reduced value,\n*element* is the current element, *key* is the current key (the current index if *container* is an Array,\nor the current property's name if *container* is an object), *container* is the original container,\nand *callback* is the completion's callback.\n\nEach `element` is processed one at a time, in **series**.\n**Calling `.parallel()` on this `async.Plan` has no effect, it will process jobs one at a time anyway.**\n\nIf the *iterator* fails for one element, the whole process *aborts and fails*.\n\n**If you do \\*NOT\\* provide a default aggregatedValue in the `async.Plan`, then the `.exec()` method require an initial *aggregatedValue* as its first argument.**\n\nNote that `async.reduce( initialAggregatedValue , container , iterator )` is equal to\n`async.do( container ).iterator( iterator ).aggregator( true , true , initialAggregatedValue )`.\n\nExample:\n```js\nvar myArray = [ 'my' , 'wonderful' , 'result' ] ;\n\nvar plan = async.reduce( myArray , function( aggregate , element , callback ) {\n\t\n\tsetTimeout( function() {\n\t\t// Asyncly calculate the sum of the length\n\t\tcallback( null , aggregate + element.length ) ;\n\t} , 0 ) ;\n} )\n// No aggregatedValue is provided in the async.Plan creation,\n// so the first argument of exec() must be the initial aggregatedValue.\n.exec( 0 , function( error , results ) {\n\t// we expect results to be equal to 17\n\texpect( results ).to.be.eql( 17 ) ;\n} ) ;\n```\n\n\n\n<a name=\"ref.async.while.do\"></a>\n### async.while( whileCallback ).do( jobsList )\n\n* [whileCallback](#ref.callback.whileCallback) `Function( error , results , logicCallback )` triggered for checking if we have to continue or not, where:\n\t* error `mixed` any truthy means error\n\t* results `Array` or `Object` that maps the *jobsList*\n\t* logicCallback `Function( [error] , loopAgain )` where:\n\t\t* error `mixed` any truthy means error\n\t\t* loopAgain `Boolean` anything else is considered either *truthy* or *falsy*\n* jobsList `Array` or `Object`\n\nIt performs an async while loop.\nThis is equivalent to javascript code:\n```js\nwhile ( expression ) {\n\t// do something\n}\n```\n\nUnlike others factories, in order to mimic native language syntax, this factory accepts a [*whileCallback*](#ref.callback.whileCallback) \nrather than a job's list. \nSo you have to use the `async.Plan`'s `.do()` method to pass the job's list.\n\nAsync while loops behave diffently than other `async.Plan` in various way:\n* it first performs an async conditional check, if the outcome is falsy, then the execution is immediately aborted\n* it performs jobs, just the way other `async.Plan` do, but:\n* when everything is done, it performs again a conditional check, and if its outcome is truthy, it loops again (and again, etc...)\n* when the outcome of the conditional check is falsy, callbacks (*finally, then, catch, else*) are triggered \nwith the results of the last iteration only (if any), so older iteration's results are lost unless checked and used\nin the [*whileCallback*](#ref.callback.whileCallback).\n\nExample:\n```js\nasync.while( function( error , results , logicCallback ) {\n\t// If doMoreWorksFunction() triggers its callback demanding another loop...\n\tlogicCallback( results.moreWorks[ 1 ] === 'loop' ) ;\n} )\n.do( {\n\tpreliminaries: doPreliminariesFunction ,\n\tworks: doWorksFunction ,\n\tmoreWorks: doMoreWorksFunction\n} ) \n.exec( function( error , results ) {\n\t// 'results' contains only the results of the last loop\n\tthingsToDoWhenFinished() ;\n} ) ;\n```\n\n\n\n<a name=\"ref.async.do.while\"></a>\n### async.do( jobsList ).while( whileCallback )\n\n* jobsList `Array` or `Object`\n* [whileCallback](#ref.callback.whileCallback) `Function( error , results , logicCallback )` triggered for checking if we have to continue or not, where:\n\t* error `mixed` any truthy means error\n\t* results `Array` or `Object` that maps the *jobsList*\n\t* logicCallback `Function( [error] , loopAgain )` where:\n\t\t* error `mixed` any truthy means error\n\t\t* loopAgain `Boolean` anything else is considered either *truthy* or *falsy*\n\nIt performs an async do-while loop.\n\nIt works exactly the same as [async.while().do()](#ref.async.while.do), except that, by default, the [*whileCallback*](#ref.callback.whileCallback)\nis triggered at the end of the process rather than at the beginning.\nThis is equivalent to javascript code:\n```js\ndo {\n\t// do something\n} while ( expression )\n```\n\n\n\n<a name=\"ref.factories.conditional\"></a>\n## *Conditional* family factories\n\nThe following factories instanciate `async.Plan` of the *conditional* family.\nThere are few differencies with `async.Plan` of the *do* family.\n\nJobs have three type of outcome: true, false and error.\n\nJobs should trigger their callback this way: `callback( [error] , result )`.\nIn this case, you are not forced to pass the error argument first.\nHowever, if you pass only one argument, it will be assumed to be an error only if it is an instance of `Error`.\n\nIf an error occurs, it will stop processing any new jobs by default.\nIf *true* or *false* is the outcome, then it all depends on the type of conditional.\n\nThere are two mode: boolean or not.\nWhen boolean mode is used, any non-error outcome are cast to a boolean value.\nIn non-boolean mode, the final outcome is simply the outcome of the last processed job.\nThe non-boolean mode is in line with the way javascript handle expression like `myVar1 && myVar2`\n(it will produce *myVar1* if *myVar1* is falsy, else *myVar2*).\n\nBy default, jobs are performed in series, one at a time.\nIt is possible to parallelize jobs processing, but it can change the final outcome in non-boolean mode,\nthough the truthness of that outcome remains unchanged.\n\n\n\n<a name=\"ref.async.and\"></a>\n### async.and( jobsList )\n\n* jobsList `Array` or `Object`\n\nIt performs an async conditional *AND*, so it keeps processing jobs as long as the outcome is truthy.\n\nBy default, it uses the non-boolean mode, so the final outcome is the outcome of the last job.\n\n\n\n<a name=\"ref.async.or\"></a>\n### async.or( jobsList )\n\n* jobsList `Array` or `Object`\n\nIt performs an async conditional *OR*, so it keeps processing jobs as long as the outcome is falsy.\n\nBy default, it uses the non-boolean mode, so the final outcome is the outcome of the last job.\n\n\n\n<a name=\"ref.async.if.and\"></a>\n### async.if.and( jobsList )\n\n* jobsList `Array` or `Object`\n\nIt performs an async conditional *AND*, so it keeps processing jobs as long as the outcome is truthy.\n\nBy default, it uses the boolean mode, so the final outcome is a boolean.\n\n\n\n<a name=\"ref.async.if.or\"></a>\n### async.if.or( jobsList )\n\n* jobsList `Array` or `Object`\n\nIt performs an async conditional *OR*, so it keeps processing jobs as long as the outcome is falsy.\n\nBy default, it uses the boolean mode, so the final outcome is a boolean.\n\n\n\n<a name=\"ref.nested\"></a>\n### Nested condition\n\nWe can create nested conditional statement just like in native language. See the following example:\n\n```js\nasync.if.and( [\n\tifSomeConditionsAreMetAnd\n\tasync.or( [\n\t\tifSomeMoreConditionsAreMet\n\t\torIfSomeAlternativeConditionsAreMet\n\t] )\n] )\n.then( function() {\n\t// Do something if the async conditional statement is true\n} )\n.else( function() {\n\t// Do something if the async conditional statement is false\n} )\n.exec() ;\n```\n`ifSomeConditionsAreMetAnd`, `ifSomeMoreConditionsAreMet` and `orIfSomeAlternativeConditionsAreMet` \nare user functions asyncly checking if some conditions are met or not.\n\nThis works because if a job is an instance of `async.Plan`, the `.exec()` method will be used as a callback.\n\nWe can use as many nested async conditional as we want.\n\n\n\n<a name=\"ref.async.Plan\"></a>\n## Class async.Plan\n\nEach factory come with a default set of behaviour. \nAlmost all behaviours can be modified by methods.\n\nHowever, modifier methods have no effect as soon as an `.exec()` family method is used on the current `async.Plan`.\n\n\n\n<a name=\"ref.async.Plan.do\"></a>\n### .do( jobsList )\n\n* jobsList `Array` or `Object`\n\nIt set the job's list.\nMost of time, the job's list is already passed as the first argument of a factory, so we don't have to use this method.\n\nHowever, it is used in the [`async.while().do()`](#ref.async.while) scheme, to mimic common programming language syntax.\n\n\n\n<a name=\"ref.async.Plan.parallel\"></a>\n### .parallel( [parallelLimit] )\n\n* parallelLimit `Number`, if omited or true: `Infinity`, if false: 1\n\nIt set the parallel limit or concurrency limit.\nThis is the number of async jobs that can be running/pending at a time.\n\nUsing a parallel limit value of 1, jobs are processed one at a time, like `async.series()` factory does.\n\nUsing a parallel limit value of Infinity, jobs are processed all at once (if they are async),\nlike `async.parallel()` factory does.\n\nUsing a parellel limit value of 3, for example, the first three jobs will start at once, when one jobs\ntriggers its callback the fourth job starts, when another job triggers its callback then the fifth job starts,\nand so on...\n\n\n\n<a name=\"ref.async.Plan.race\"></a>\n### .race( raceMode )\n\n* raceMode `Boolean`, if omited: `true`\n\nSet the *race* mode.\n\nIn *race* mode, the whole jobs processing aborts when the first job finish without error.\n\nSee [`async.race()`](#ref.async.race) factory.\n\n\n\n<a name=\"ref.async.Plan.waterfall\"></a>\n### .waterfall( waterfallMode )\n\n* waterfallMode `Boolean`, if omited: `true`\n\nSet the *waterfall* mode.\n\nIn *waterfall* mode, each job is called with the previous job output as arguments,\nand the first job receives arguments directly from `.exec()`.\n\nSee [`async.waterfall()`](#ref.async.waterfall) factory.\n\n\n\n<a name=\"ref.async.Plan.while\"></a>\n### .while( whileCallback , whileActionBefore )\n\n* [whileCallback](#ref.callback.whileCallback) `Function( error , results , logicCallback )` triggered for checking if we have to continue or not, where:\n\t* error `mixed` any truthy means error\n\t* results `Array` or `Object` that maps the *jobsList*\n\t* logicCallback `Function( [error] , loopAgain )` where:\n\t\t* error `mixed` any truthy means error\n\t\t* loopAgain `Boolean` anything else is considered either *truthy* or *falsy*\n* whileActionBefore `Boolean`, if omited: `false`\n\nSet a *while* loop mode.\n\nThe argument *whileActionBefore* is used to define if the condition should be evaluated at the begining of the loop\nor at the end of the loop.\n\nSee [async.while().do()](#ref.async.while.do) (if *whileActionBefore* is true) or\n[async.do().while()](#ref.async.do.while) (if *whileActionBefore* is false) for details.\n\n\n\n<a name=\"ref.async.Plan.repeat\"></a>\n### .repeat( n )\n\n* n `Number`\n\nSet loop mode, the job's list will run *n* times.\n\nActually this is a shortcut, it simply set up a *while* loop with a trivial callback.\nAvoid to reinvent the wheel again and again.\n\nSee [.while()](#ref.async.Plan.while) for details.\n\n\n\n<a name=\"ref.async.Plan.fatal\"></a>\n### .fatal( [errorsAreFatal] )\n\n* errorsAreFatal `Boolean`, if omitted: true\n\nIf errors are fatal (the default in most factories), then whenever a job fails the whole process is aborted immediately.\n\nIf error are not fatal, others jobs will be processed even if some errors occurs.\n\n\n\n<a name=\"ref.async.Plan.boolean\"></a>\n### .boolean( [castToBoolean] )\n\n* castToBoolean `Boolean`, if omitted: true\n\nThis only have effects in *Conditional* family `async.Plan`.\n\nIf *castToBoolean* is true, the outcome of jobs and the final outcome is always `true` or `false`:\nthis is what happens with `async.if.and()` and `async.if.or()` factories by default.\n\nIf *castToBoolean* is false, the outcome of each job remains unchanged, and the final outcome is \nthe outcome of the last job: this is what happens with `async.and()` and `async.or()` factories by default.\n\n\n\n<a name=\"ref.async.Plan.transmitError\"></a>\n### .transmitError( [transmit] )\n\n* transmit `Boolean`, if omitted: true\n\nThis only have effects in waterfall mode, using `async.waterfall()` factory.\n\nIf *transmit* is true, each job received the *error* argument of the previous job.\n\nIf *transmit* is false, the *error* argument pass by the previous job is not transmitted.\n\nExample with `.transmitError`:\n```js\nasync.waterfall( [\n\tfunction( str , callback ) {\n\t\t// str equals 'oh', passed by .exec()'s first argument\n\t\tcallback( null , str + ' my' ) ;\n\t} ,\n\tfunction( lastError , str , callback ) {\n\t\t// lastError equals null\n\t\t// str equals 'oh my', passed by the previous job\n\t\tcallback( new Error() , str + ' wonderful' ) ;\n\t} ,\n\tfunction( lastError , str , callback ) {\n\t\t// lastError is now an instance of Error\n\t\t// str equals 'oh my wonderful', passed by the previous job\n\t\tcallback( null , str + ' result' ) ;\n\t}\n] )\n.transmitError( true )\n.fatal( false )\n.exec( 'oh' , function( error , results ) {\n\t// output 'oh my wonderful result'\n\tconsole.log( results ) ;\n} ) ;\n```\n\n\n\n<a name=\"ref.async.Plan.timeout\"></a>\n### .timeout( [jobsTimeout] )\n\n* jobsTimeout `undefined` or `Number` (in ms), if omited: `undefined`\n\nSet up a time limit for each job.\nIf a job doesn't trigger its callback within this time, its callback is triggered anyway automatically with an error:\n`new Error( 'Timeout' )`.\n\nIf the job triggers its callback later, it will be ignored.\n\nIt comes in handy in any network or service dependant async jobs, like database queries, HTTP request, and so on.\n\nAlso this is **IMPORTANT** to understand that this is the async-kit lib who is responsible for the timeout to kick in:\nthe user code is still in execution, it may be pending, waiting for I/O to perform some other tasks.\nThe timeout feature give us the chance to be sure that our callback get triggered within some time limit, **it doesn't\ninterupt the job in any way**.\n\n\n\n<a name=\"ref.async.Plan.retry\"></a>\n### .retry( [maxRetry] , [baseTimeout] , [multiply] , [maxTimeout] )\n\n* maxRetry `Number`, it doesn't update if omited\n* baseTimeout `Number` in **ms**, it doesn't update if omited\n* multiply `Number`, it doesn't update if omited\n* maxTimeout `Number`, in **ms**, it doesn't update if omited\n\nThis modifier allows jobs in error to be retried.\n\nThis is a very nice feature when dealing with other servers or external services, because they could be unavailable at any time,\nbut we don't want important tasks to fail.\n\nIt allows fine tuning:\n* maxRetry: the maximum number of times a job should be retried, before giving up with the last error\n* baseTimeout: the base timeout in **ms** before retrying, this is the timeout before the first retry\n* multiply: the timeout before retrying is multiplied by this value for each new retry\n* maxTimeout: the maximum timeout in **ms**, it will never be more despite the increasing retries with a multiply value > 1.\n\nFor example, assuming `maxRetry: 6, baseTimeout: 100, multiply: 1.5, maxTimeout: 500`, we will get for each retry \nthe timeout value:\n* 1st - 100ms\n* 2nd - 150ms (=100*1.5)\n* 3rd - 225ms (=150*1.5)\n* 4th - 338ms (=225*1.5)\n* 5th - 500ms (capped by maxTimeout)\n* 6th - 500ms (capped by maxTimeout)\n\nA good practice is to specify a low *baseTimeout*, around 10ms, and a high *multiply* value, at least 2.\nThis way, things keep reactive when a sporadic error occurs, but if something is really wrong with some of our servers,\nwe didn't flood them to death, we give them a chance to recover.\n\nIf *maxRetry* is high, we may consider using a *maxTimeout* value, between 10 seconds and 2 minutes.\nThis could be really bad if some actions are retried few hours or few days later, totally out of context.\n\nBy the way, those are general guidance, it all depends on the criticy of the tasks, wheither it involves local, lan, vlan\nor internet networks, and more importantly: if those actions take place behind the scene or if some end-user are currently\nexpecting results quickly.\n\nExample, with some *behind the scene* *cron*-like tasks, involving third-party services:\n```js\nasync.parallel( [\n\tretrieveSomeRSS ,\n\tquerySomeThirdPartyAPI ,\n\tqueryMoreThirdPartyAPI\n] )\n// At most 100 retries, starting with a 100 ms timeout before retrying,\n// multiplying timeout by 2 at each new try but capped at 10 minutes timeout\n.retry( 100 , 100 , 2 , 60000 )\n.exec( function( error , results ) {\n\t// update your local database or cache\n} ) ;\n```\n\n\n\n<a name=\"ref.mixing.timeout.retry\"></a>\n### Mixing .timeout() & .retry()\n\nMixing `.timeout()` and `.retry()` can be extremely powerful.\n\nSometime a task can end up pending a long time, because some bugs occurs, but a retry can eventually succeed immediately: \nprobably we sent a request on some third-party, we get load-balanced to a server that do not respond anymore, but issuing\na new request may end up to a server that still works well.\n\nThis is exactly what can achieve a mix of `.timeout()` and `.retry()`: when the *timeout* is reached for a job,\nit triggers its callback with a failed status (`new Error( 'Timeout' )`), then *retry* kick in and the job start over,\nit may hit the time limit again and be restarted again, until it succeeds or the retry countdown abort the whole process.\n\nAlso there are **IMPORTANT** drawback we need to be aware of:\n* when a timeout occurs, the job is **\\*NOT\\*** interupted in any way (see [`.timeout()`](#ref.async.Plan.timeout) for details)\n* so when successive retries kick in, the same job can run multiple times: our job's code should support that without\n  messing our database for example\n* also if a job timeout and is retried, the first try *may* finally succeed before the second try complete: our job's\n  code should support that case too\n\nAs a rule of thumb, if we plan to mix `.timeout()` and `.retry()`, we must isolate as much as possible critical code,\ncreating more jobs that perform small task is better.\n\nFor example, this is a **\\*VERY\\* bad** practice:\n```js\nasync.do( [\n\tqueryMultipleExternalServicesAndThenUpdateOurLocalDatabaseAccordingly\n] )\n.timeout( 100 )\n.retry( 100 , 100 , 2 , 60000 )\n.exec( function( error , results ) {\n\tconsole.log( 'Done!' ) ;\n} ) ;\n```\n\nWe have to consider rewriting it this way:\n```js\nasync.parallel( [\n\tqueryExternalService1 ,\n\tqueryExternalService2 ,\n\tqueryExternalService3\n] )\n.timeout( 100 )\n.retry( 100 , 100 , 2 , 60000 )\n.exec( function( error , results ) {\n\tif ( ! error ) {\n\t\tupdateOurLocalDatabaseAccordingly( results ) ;\n\t}\n} ) ;\n```\n\nIn the last snippet, we have isolated jobs that can timeout due to things that are out of our control.\nIf one query failed, we don't have to restart from scratch, re-doing queries that have already succeeded.\nFinally, moving `updateOurLocalDatabaseAccordingly()` into the [*finallyCallback*](#ref.callback.finallyCallback)\nof `.exec()` allows us to use the parallel mode, so the whole process perform faster.\nIf we had chosen to put this function into a job, we would have been constrained to use an `async.series()` factory.\nMore important: we are sure that the code that update our database will run once.\n\n\n\n<a name=\"ref.async.Plan.lastJobOnly\"></a>\n### .lastJobOnly( [returnLastJobOnly] )\n\n* returnLastJobOnly `boolean`, if omited: `true`\n\nIf set to `true`, only the last job pass its result to [*finallyCallback*](#ref.callback.finallyCallback),\n[*thenCallback*](#ref.callback.thenCallback) etc...\n\nWithout `.lastJobOnly()` (the default in most factories):\n```js\nasync.series( [\n\tfunction( callback ) { callback( null , 'my' ) ; } ,\n\tfunction( callback ) { callback( null , 'wonderful' ) ; } ,\n\tfunction( callback ) { callback( null , 'result' ) ; }\n] )\n.exec( function( error , result ) {\n\t// result equals `[ [ null , 'my' ], [ null , 'wonderful' ], [ null , 'result' ] ]`\n} ) ;\n```\n\nWith `.lastJobOnly()` (default in `async.waterfall()` and `async.race()` factories):\n```js\nasync.series( [\n\tfunction( callback ) { callback( null , 'my' ) ; } ,\n\tfunction( callback ) { callback( null , 'wonderful' ) ; } ,\n\tfunction( callback ) { callback( null , 'result' ) ; }\n] )\n.lastJobOnly()\n.exec( function( error , result ) {\n\t// result equals `'result'`\n} ) ;\n```\n\n**BE CAREFUL:** when using `.lastJobOnly()` in parallel mode, this is the job that finish last which transmits its results.\nThis is **\\*NOT\\* necessarly** the last job in the job's list.\nNote that `.lastJobOnly()` is used in `async.race()` factory, but here the whole process abort when the first job finish\nwithout error, so the first job and the last job are the same.\n\n\n\n<a name=\"ref.async.Plan.mapping1to1\"></a>\n### .mapping1to1( [returnMapping1to1] )\n\n* returnMapping1to1 `Boolean`, if omited: `true`\n\nIf set to `true`, the *results* directly map the *jobsList*.\nIt is used (and locked) in `async.map()` factory.\n\nIf set to `false`, the *results* contains for each entry, the whole argument's list\npassed by the job's callback.\n\nWithout `.mapping1to1()` (the default in most factories):\n```js\nasync.parallel( [\n\tfunction( callback ) { callback( null , 'my' ) ; } ,\n\tfunction( callback ) { callback( null , 'wonderful' ) ; } ,\n\tfunction( callback ) { callback( null , 'result' ) ; }\n] )\n.exec( function( error , results ) {\n\t// results equals `[ [ null , 'my' ], [ null , 'wonderful' ], [ null , 'result' ] ]`\n} ) ;\n```\n\nWith `.mapping1to1()` (the default in `async.map()` factory):\n```js\nasync.map( [\n\tfunction( callback ) { callback( null , 'my' ) ; } ,\n\tfunction( callback ) { callback( null , 'wonderful' ) ; } ,\n\tfunction( callback ) { callback( null , 'result' , 'extra argument that will be dropped' ) ; }\n] )\n.exec( function( error , results ) {\n\t// results equals `[ 'my' , 'wonderful' , 'result' ]`\n} ) ;\n```\n\n**Note:** when using `.mapping1to1()`, any extra arguments passed to the job's callback are ignored.\n\n\n\n<a name=\"ref.async.Plan.using\"></a>\n### .using( various )\n\n* various `Function`, `Array` or `Object`\n\nArgument passed to `.using()` is used in combination with the job's list.\nBehaviours all depend on the type of the arguments.\n\nIn the following `.using()` variation, `async.do()` can be replaced by any `async.Plan`'s factory.\n\n#### async.do( jobsData ).using( workerFunction )\n\n* jobsData `Array` (or `Object`) of `Array`\n* workerFunction `Function`\n\nWhen combining `.do()` and `.using()` this way, each job contains an array of arguments to pass to *workerFunction*.\n\nExample:\n\n```js\nasync.do( [\n\t[ 'http://example.com/' , 500 ] ,\n\t[ 'http://example.com/forum/' , 800 ] ,\n\t[ 'http://example.com/blog/' , 200 ]\n] )\n.using( function( url , timeout ) {\n\t// Async check of url, with some timeout\n} )\n.exec( function( error , results ) {\n\tif ( ! error )  { console.log( \"Success!\" ) ; }\n} ) ;\n```\n\nAlso, if your *workerFunction* only accepts one argument, you can avoid *Array of Array* construct:\n\n```js\nasync.do( [\n\t'http://example.com/' ,\n\t'http://example.com/forum/' ,\n\t'http://example.com/blog/'\n] )\n.using( function( url ) {\n\t// Async check of url\n} )\n.exec( function( error , results ) {\n\tif ( ! error )  { console.log( \"Success!\" ) ; }\n} ) ;\n```\n\n#### async.do( jobsList ).using( args )\n\n* jobsList `Array` (or `Object`) of `Function`\n* args `Array`\n\nThis is the opposite.\nHere we have a list of different function, but they take the same arguments.\n\n\nExample:\n```js\nasync.do( [\n\tdnsResolve ,\n\tping ,\n\thttpGet\n] )\n.using( 'http://example.com/' )\n.exec( function( error , results ) {\n\tif ( ! error )  { console.log( \"Success!\" ) ; }\n} ) ;\n```\n\nIn the previous snippet, `.using()` provide the data, and `.do()` provide the actions, where *dnsResolve*, *ping*\nand *httpGet* are three functions that take an URL as their first arguments. The *dnsResolve* function will convert\nthe URL into an IP addresse, then *ping* will er... ping this IP, and finally *httpGet* will forge an HTTP request\nand get the page content.\n\n\n\n<a name=\"ref.async.Plan.iterator\"></a>\n### .iterator( iteratorFunction )\n\n* iteratorFunction `Function( element , [key] , [container] , callback )` where:\n\t* element `mixed` the current array element or object's property value\n\t* key `Number` or `String` the current key (index for array, property name for object)\n\t* container `Array` or `Object`, this is the original container\n\t* callback `Function( error , [arg1] , [arg2] , ... )` a node-style callback to trigger on completion\n\nWith `.iterator( iteratorFunction )` our jobs become data for *iteratorFunction*. \nThis is close to the behaviour of `.using( workerFunction )`, except that an iterator function is not called the same way.\n\nRather than processing each element of the `Array` as an array of arguments, here the whole element is passed as the\nfirst argument of the iterator.\n\nIn fact, `async.do( container ).iterator( iteratorFunction )` is equal to `async.foreach( container , iteratorFunction )`.\n\nSee [async.foreach()](#ref.async.foreach) for details.\n\n\n\n<a name=\"ref.async.Plan.aggregator\"></a>\n### .aggregator( transmitAggregate , returnAggregate , defaultAggregate )\n\n* transmitAggregate `Boolean`, if omited: `true`\n* returnAggregate `Boolean`, if omited: `true`\n* defaultAggregate `mixed`, this is the default value\n\nThis set or unset the current `async.Plan` as an aggregator.\n\nNote that `async.do( container ).iterator( iterator ).aggregator( true , true , initialAggregatedValue )`\nis equal to `async.reduce( initialAggregatedValue , container , iterator )`.\nFor more details, see [async.reduce()](#ref.async.reduce).\n\nIf *transmitAggregate* is set, then the *iterator* (or job's function) receive the current *aggregatedValue*\nas its first argument, all other arguments being shifted to the right.\n\nIf *returnAggregate* is set, then the *results* passed to callback (*then*, *catch* and *finally* callback)\nonly contains the *aggregatedValue*.\n\nIf *defaultAggregate* is set, this is what will be used as the starting value for *aggregatedValue*.\n\n\n\n<a name=\"ref.async.Plan.nice\"></a>\n### .nice( niceness )\n\n* niceness `Number`, any number is ok but recommended values are between *-20* and *+20*\n\nThis try to mimic the unix command `nice` and `renice`.\nThis set up how the job's scheduler behaves.\n\nIt depends on the *niceness* value:\n* *<=-2* is for synchronous scheduling: the scheduler process as fast as possible, if jobs provided by user are synchronous,\n  everything will be synchronous and will be executed in one code flow for at most *N* recursion, where *N=1* for *nice=-2*,\n  *N=2* for *nice=-3*, *N=3* for *nice=-4*, and so on... When the maximum recursion counter is reached, the next job will\n  use `setImmediate()` internally. This prevent from the *Maximum call stack size exceeded* error when callbacks are synchronous,\n  and give some breath for I/O when dealing with CPU-bound tasks. As long as things are synchronous, there will be no\n  difference between `async.series()` or `async.parallel()`. \n* *-1* is for asynchronous scheduling, it uses `setImmediate()` internally. This scheduling allows I/O to be performed\n  (see [setImmediate()](http://nodejs.org/api/timers.html#timers_setimmediate_callback_arg) for details).\n* *>=0* is for asynchronous scheduling, it uses `setTimeout()` internally. This scheduling allows I/O to be performed\n  and much more. The *niceness* value is used as the delay for `setTimeout()`, so using `.nice(10)`\n  means that the scheduler will delay further action for 10ms\n  (see [setTimeout()](http://nodejs.org/api/timers.html#timers_settimeout_callback_delay_arg) for details).\n\nSee [NextGen Event nice feature](https://www.npmjs.com/package/nextgen-events#ref.note.nice) for references.\n\nBy default, if `.nice()` is not called, the nice value is -20 (i.e. synchronous for at most 19 recursions).\n\nFull synchronous scheduling may cause *Maximum call stack size exceeded* issues if loop, `.retry()` or just an huge job's\nlist is involved, because everything use nested callback the way we would have done it, those nested callback are just\nabstracted away by the lib, but still remains behind the scene.\nThat's why **starting at v0.6.0**, there isn't full synchronous scheduling anymore: once in a while, an asynchronous call\nwill be triggered. Do not drop the nice value below -20, which provide at most 19 recursions.\n\nAsynchronous scheduling uses the javascript's *event loop*, so there is no more infinite nested callback possible.\nIt can scale better for big job's list, loop and `.retry()`...\n\nIf we have a big synchronous task to do, we can divide it into many jobs, then use for example:\n```js\nasync.series( jobsList ).nice( 0 ).exec() ;\n```\n... to *asyncify* it a bit. This can be very important for services: our application must keep accepting\nnew request during the big task processing. Also if the task is really that big, it is usually a good practice \nto spawn a process or create a new specific service for this particular task anyway.\n\n\n\n<a name=\"ref.async.Plan.then\"></a>\n### .then( thenCallback )\n\n* [thenCallback](#ref.callback.thenCallback) `Function( results )`\n\t* results `mixed`, depends on options\n\nThis set up a *then* callback part of the `async.Plan` itself.\nSee [thenCallback](#ref.callback.thenCallback) for details.\n\n\n\n<a name=\"ref.async.Plan.else\"></a>\n### .else( elseCallback )\n\n* [elseCallback](#ref.callback.elseCallback) `Function( results )`\n\t* results `mixed`, depends on options\n\nThis set up an *else* callback part of the `async.Plan` itself.\nSee [elseCallback](#ref.callback.elseCallback) for details.\n\nThis has no effect for *Do* family `async.Plan`.\n\n\n\n<a name=\"ref.async.Plan.catch\"></a>\n### .catch( catchCallback )\n\n* [catchCallback](#ref.callback.catchCallback) `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n\nThis set up a *catch* callback part of the `async.Plan` itself.\nSee [catchCallback](#ref.callback.catchCallback) for details.\n\n\n\n<a name=\"ref.async.Plan.finally\"></a>\n### .finally( finallyCallback )\n\n* [finallyCallback](#ref.callback.finallyCallback) `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n\nThis set up a *finally* callback part of the `async.Plan` itself.\nSee [finallyCallback](#ref.callback.finallyCallback) for details.\n\n\n\n<a name=\"ref.async.Plan.clone\"></a>\n### .clone()\n\nThis method is used to clone an `async.Plan` and return it.\n\nThe cloned `async.Plan` is **unlocked**: we can use its modifier methods even if the original `async.Plan` is locked\nor is currently under execution.\n\n\n\n<a name=\"ref.async.Plan.export\"></a>\n### .export( [execMethod] )\n\n* execMethod `String`, one of *'exec'*, *'execKV'*, *'execFinally'*, *'execThenCatch'*, *'execThenElse'*, *'execThenElseCatch'*\n  and *'execArgs'*... if omited: 'exec'\n\nThis export and return an `async.Plan` as a function.\n\nBy default, the exported function behaves exactly like the `.exec()` method of the `async.Plan`.\nIf we want to export a different `.exec()`-like method, we can provide the method's name as the argument of `.export()`.\n\nSince the `async.Plan` is internally cloned, changes made on the original `async.Plan` do **not** change how the exported function behaves.\n\n\n\n<a name=\"ref.async.Plan.exec\"></a>\n### .exec( ... )\n\nThis method execute the `async.Plan`.\n\nUntil an exec-like method is called, nothing happens at all, previous methods mostly configure the `async.Plan`.\n\nArguments passed to `.exec()` depend on factories by default, and can be modified by [`.execMapping()`](#ref.async.Plan.execMapping).\n\nHowever, most factories use this scheme:\n\n`.exec( [arg1] , [arg2] , ... , [finallyCallback](#ref.callback.finallyCallback) )`.\n\n* arg1, arg2, ... `mixed` : arguments to pass to all the jobs (or to the first job only in *waterfall* mode)\n* [finallyCallback](#ref.callback.finallyCallback) `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n\nFollowing `.exec()`-like methods have a static scheme, and are not modified by [`.execMapping()`](#ref.async.Plan.execMapping).\n\n\n\n<a name=\"ref.async.Plan.execFinally\"></a>\n### .execFinally( finallyCallback )\n\n* [finallyCallback](#ref.callback.finallyCallback) `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n\nThis method execute the `async.Plan`, just like [`.exec()`](#ref.async.Plan.exec).\nIt only accepts one argument: the [finallyCallback](#ref.callback.finallyCallback).\n\n\n\n<a name=\"ref.async.Plan.execThenCatch\"></a>\n### .execThenCatch( thenCallback , catchCallback , [finallyCallback] )\n\n* [thenCallback](#ref.callback.thenCallback) `Function( results )`\n\t* results `mixed`, depends on options\n* [catchCallback](#ref.callback.catchCallback) `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n* [finallyCallback](#ref.callback.finallyCallback) `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n\nThis method execute the `async.Plan`, just like [`.exec()`](#ref.async.Plan.exec).\nLike the name suggests, the first argument should be the [thenCallback](#ref.callback.thenCallback), and\n[catchCallback](#ref.callback.catchCallback) as the second.\n\nHowever, the [finallyCallback](#ref.callback.finallyCallback) can still be passed as the third argument.\n\n\n\n<a name=\"ref.async.Plan.execThenElse\"></a>\n### .execThenElse( thenCallback , elseCallback , [finallyCallback] )\n\n* [thenCallback](#ref.callback.thenCallback) `Function( results )`\n\t* results `mixed`, depends on options\n* [elseCallback](#ref.callback.elseCallback) `Function( results )`\n\t* results `mixed`, depends on options\n* [finallyCallback](#ref.callback.finallyCallback) `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n\nThis method execute the `async.Plan`, just like [`.exec()`](#ref.async.Plan.exec).\nLike the name suggests, the first argument should be the [thenCallback](#ref.callback.thenCallback), and\n[elseCallback](#ref.callback.elseCallback) as the second.\n\nHowever, the [finallyCallback](#ref.callback.finallyCallback) can still be passed as the third argument.\n\n\n\n<a name=\"ref.async.Plan.execThenElseCatch\"></a>\n### .execThenCatch( thenCallback , elseCallback , catchCallback , [finallyCallback] )\n\n* [thenCallback](#ref.callback.thenCallback) `Function( results )`\n\t* results `mixed`, depends on options\n* [elseCallback](#ref.callback.elseCallback) `Function( results )`\n\t* results `mixed`, depends on options\n* [catchCallback](#ref.callback.catchCallback) `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n* [finallyCallback](#ref.callback.finallyCallback) `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n\nThis method execute the `async.Plan`, just like [`.exec()`](#ref.async.Plan.exec).\nLike the name suggests, the first argument should be the [thenCallback](#ref.callback.thenCallback),\n[elseCallback](#ref.callback.elseCallback) as the second, and [catchCallback](#ref.callback.catchCallback) as the third.\n\nHowever, the [finallyCallback](#ref.callback.finallyCallback) can still be passed as the fourth argument.\n\n\n\n<a name=\"ref.async.Plan.execArgs\"></a>\n### .execArgs( [arg1] , [arg2] , ... )\n\n* arg1, arg2, ... `mixed`\n\nThis method execute the `async.Plan`, just like [`.exec()`](#ref.async.Plan.exec).\nAll arguments passed to this method are passed to all the jobs (except in *waterfall* mode, where they are passed only to the first job).\n\n\n\n<a name=\"ref.async.Plan.execMapping\"></a>\n### .execMapping( config )\n\n* config `Object`\n\t* .aggregateArg `Boolean`, if omited: `false`\n\t* .minInputs `Number` (integer), if omited: 0\n\t* .maxInputs `Number` (integer), if omited: 0\n\t* .inputsName `Array` of `String` describing each input (only used for function signature), if omited: `[]`\n\t* .callbacks `Array` of `String` (can only be: 'then', 'else', 'catch' and 'finally'), if omited: `[]`\n\nThis method is used to configure [`.exec()`](#ref.async.Plan.exec)'s behaviour.\n\nIf `config.aggregateArg` is `true`, the first argument of `.exec()` is the aggregate's value.\n\nIf `config.maxInputs` is greater than 0, the next arguments of `.exec()` **\\*MAY\\*** be inputs for jobs (arguments passed to them).\nIf `config.minInputs` is greater than 0, the next arguments of `.exec()` **\\*MUST\\*** be inputs for jobs.\nIn fact, `.exec()` supports variable number of arguments.\n\nNote that in *waterfall* mode, inputs arguments are only passed to the first job.\n\nFinally, if `config.callbacks` is not an empty array, the last arguments are callback, strictly in the order defined.\n\n`.exec()` supports variable number of arguments:\n\n* if `config.minInputs` and `config.maxInputs` are equals, the number of inputs arguments are fixed,\n  so the number of callback is variable: some callback could be omited\n\n* if `config.minInputs` and `config.maxInputs` are **\\*NOT\\*** equals, the number of inputs arguments are variable,\n  so the number of callback is fixed (if it wasn't, we couldn't have a clue weither an argument is an input or a callback)\n\n\nExample using the `async.Plan` property `.execMappingSignature` to get the **signature** of `.exec()`, here with variable number of inputs:\n```js\nvar plan = async.do( [\n\t// Some jobs\n] )\n.execMapping( {\n\tcallbacks: [ 'then' , 'catch' ] ,\n\tminInputs: 0 ,\n\tmaxInputs: 2 ,\n\tinputsName: [ 'firstArg' , 'secondArg' ]\n} ) ;\n\nconsole.log( plan.execMappingSignature ) ;\n// produce: ( [firstArg], [secondArg], thenCallback, catchCallback )\n```\n\n\nExample with fixed number of inputs:\n```js\nvar plan = async.do( [\n\t// Some jobs\n] )\n.execMapping( {\n\tcallbacks: [ 'then' , 'catch' ] ,\n\tminInputs: 2 ,\n\tmaxInputs: 2 ,\n\tinputsName: [ 'firstArg' , 'secondArg' ]\n} ) ;\n\nconsole.log( plan.execMappingSignature ) ;\n// produce: ( firstArg, secondArg, [thenCallback], [catchCallback] )\n```\n\n\nExample with `config.aggregateArg` set to `true`:\n```js\nvar plan = async.do( [\n\t// Some jobs\n] )\n.execMapping( {\n\taggregateArg: true ,\n\tcallbacks: [ 'then' , 'catch' ] ,\n\tminInputs: 2 ,\n\tmaxInputs: 2 ,\n\tinputsName: [ 'firstArg' , 'secondArg' ]\n} ) ;\n\nconsole.log( plan.execMappingSignature ) ;\n// produce: ( aggregateValue, firstArg, secondArg, [thenCallback], [catchCallback] )\n```\n\n\n\n<a name=\"ref.async.Plan.execKV\"></a>\n### .execKV( KeyValuePairs )\n\n* KeyValuePairs `Object`\n\t* .inputs `Array` input arguments for jobs, if omited: `[]`\n\t* .aggegate `mixed` optionnal aggregate initial value\n\t* .then `Function` optionnal [thenCallback](#ref.callback.thenCallback)\n\t* .else `Function` optionnal [elseCallback](#ref.callback.elseCallback)\n\t* .catch `Function` optionnal [catchCallback](#ref.callback.catchCallback)\n\t* .finally `Function` optionnal [finallyCallback](#ref.callback.finallyCallback)\n\nThis method execute the `async.Plan`, just like [`.exec()`](#ref.async.Plan.exec).\nRather than passing arguments in a predefined order, `.execKV()` accepts an object of key-value pairs.\nThis is an alternative to `.execMapping()` & `.exec()`.\n\nPro:\n* it improves greatly the readability\n* more straightforward, no need to remember the signature of `.exec()`\n\nCons:\n* With `.execMapping()`, `.exec()` can raise error if misused, for example it constraints a number of input's arguments\n\n\n\n<a name=\"ref.callbacks\"></a>\n## Callbacks\n\nThose callbacks are triggered (if conditions are met) when the `async.Plan` is resolved.\nNote that if we don't use [`.timeout()`](#ref.async.Plan.timeout) and a job is pending forever, the `async.Plan` will never being resolved,\nthus no callback will be ever triggered.\n\nThere are two stages of callback.\n\n* The first stage are callbacks defined in the `async.Plan` itself. Those callback are **\\*ALWAYS\\*** triggered before the second stage.\n\n* The second stage are callbacks of the `.exec()`-like methods.\n\n\n\n<a name=\"ref.callback.thenCallback\"></a>\n### thenCallback\n\n* thenCallback `Function( results )`\n\t* results `mixed`, depends on options\n\nFor *Do* family, this callback is triggered if the `async.Plan`'s execution succeed. The *success* depends on factory and options used.\nUsually, an `async.Plan` succeed if no error happened. But jobs on error can be retried if [`.retry()`](#ref.async.Plan.retry) is used, and finally succeed,\n[`async.race`](#ref.async.race) succeed as long as one job succeed, and so on.\n\nFurthermore, for *Conditional* family, the final result should be `true` or *truthy* for this callback to be triggered.\n\nThe *results* argument's format passed to this callback depends on many factor.\nSee related factories and modifier.\n\n\n\n<a name=\"ref.callback.elseCallback\"></a>\n### elseCallback\n\n* elseCallback `Function( results )`\n\t* results `mixed`, depends on options\n\nIt never triggers for *Do* family `async.Plan`.\n\nFor *Conditional* family, it will trigger if the final result is `false` or *falsy*.\nHowever, if **no** [*catchCallback*](#ref.callback.catchCallback) exists for this stage (see [callbacks introduction](#ref.callbacks) for what a callback stage is),\n**it will trigger if the final outcome is an error too**.\n\n\n\n<a name=\"ref.callback.catchCallback\"></a>\n### catchCallback\n\n* catchCallback `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n\nThis callback is triggered when the final outcome is an error.\n\n\n\n<a name=\"ref.callback.finallyCallback\"></a>\n### finallyCallback\n\n* finallyCallback `Function( error , results )`\n\t* error `mixed`, depends on jobs' code\n\t* results `mixed`, depends on options\n\nThis callback is **\\*ALWAYS\\*** triggered.\nThis is the **last** callback of a stage to be triggered.\n\n\n\n<a name=\"ref.callback.whileCallback\"></a>\n### whileCallback\n\n* whileCallback `Function( error , results , logicCallback )`, where:\n\t* error `mixed` any truthy means error\n\t* results `Array` or `Object` that maps the *jobsList*\n\t* logicCallback `Function( [error] , loopAgain )` where:\n\t\t* error `mixed` any truthy means error\n\t\t* loopAgain `Boolean` anything else is considered either *truthy* or *falsy*\n\nThis callback is used for while loop.\n\nThe last iteration's *error* and *results* are passed to this function. \n\nThen the internal *logicCallback* function can be triggered, if a *truthy* value is passed as the *loopAgain* argument,\na new loop iteration will be performed, if a *falsy* value is passed, no new loop iteration will take place:\ncompletion callback (*thenCallback*, *elseCallback*, *catchCallback*, *finallyCallback*) will be triggered\ndepending on the current (last) iteration's outcome.\n\n\n\n<a name=\"ref.async.ExecContext\"></a>\n## Class async.ExecContext\n\nAn instance of `async.ExecContext` is returned by each `exec()`-like methods.\nWe can use this object to listen to some useful event.\n\n\n\n<a name=\"ref.async.ExecContext.getJobsStatus\"></a>\n### .getJobsStatus()\n\nThis method provide insightful real-time information about the status of each jobs.\nThis is designed for flow-control debugging/logging purpose, other uses are discouraged.\n\nIt returns an `Object` or an `Array` that map the jobs' list.\nFor each job, an object is given where:\n\n* job `mixed` the original job, e.g. `Function`, `Array`, `async.Plan`, etc...\n* status `string` the current status of the job, one of the following: \n\t* 'waiting': the job has not started yet, it is queued\n\t* 'pending': the job has been started, but it hasn't triggered its completion's callback yet\n\t* 'ok': the job has finished successfully\n\t* 'failed': the job has failed, it has returned an error (generic failure)\n\t* 'timeout': the job hasn't complete in time (specific failure)\n\t* 'aborted': the job has caused the whole jobs' list to abort (specific failure)\n* result `Array` the result of the job, if any... it is strictly the same format that exec()-like function\n\tpass to their callbacks\n* errors `Array` a list of errors that happened for this job, e.g. each multiple failure on retryable jobs, as well\n\tas reporting when the job has called its completion callback multiple times, and so on\n* tried `integer` the number of time the job has been tried (useful in conjunction with [.retry()](#ref.async.Plan.retry)).\n\n\n\n<a name=\"ref.async.ExecContext.event.progress\"></a>\n### Event: 'progress' ( progressStatus , [error] , results )\n\n* progressStatus `Object`, with properties:\n\t* resolved `Number` the number of resolved jobs (done/error/aborted)\n\t* ok `Number` the number of resolved jobs that have succeeded\n\t* failed `Number` the number of resolved jobs that have failed\n\t* pending `Number` the number of jobs started and still running (i.e. not *done*)\n\t* waiting `Number` the number of jobs in queue, not started yet\n\t* loop `Number` the loop iteration ([*while* loop](#ref.async.Plan.while) or [`.repeat()`](#ref.async.Plan.repeat))\n* error `mixed` the current error status, *Conditional* family `async.Plan` **DO NOT** pass this argument\n* results `Array` of `mixed` for *Do* family `async.Plan` or just `mixed` for *Conditional* family `async.Plan`, this is the partial results\n\nThe 'progress' event is fired each time a job complete.\n\nThe *progressStatus* object contains the main informations necessary to build a progress bar.\n\nOthers arguments can be useful if we need access to the partial results.\n\n\n\n<a name=\"ref.async.ExecContext.event.resolved\"></a>\n### Event: 'resolved' ( [error] , results )\n\n* error `mixed` the current error status, *Conditional* family `async.Plan` **DO NOT** pass this argument\n* results `Array` of `mixed` for *Do* family `async.Plan` or just `mixed` for *Conditional* family `async.Plan`,\n  this is the **final** results\n\nThe 'resolved' event is fired when the final result is settled.\n\nThis event triggers [*thenCallback()*](#ref.callback.thenCallback), [*elseCallback()*](#ref.callback.elseCallback),\n[*catchCallback()*](#ref.callback.catchCallback) and [*finallyCallback()*](#ref.callback.finallyCallback).\n\nIf we listen to this event, the above callbacks will always trigger first (since they have already registered).\nSo there is only few cases where it is useful to listen to it.\nSometime it can be useful to register for this event directly in jobs (using `this` which references the current \n[`async.ExecContext`](#ref.async.ExecContext) instance), so we can abort a CPU consuming job that will be ignored anyway.\n\nWhen in concurrency with others, the 'resolved' event is always fired before any others events.\n\n\n\n<a name=\"ref.async.ExecContext.event.finish\"></a>\n### Event: 'finish' ( [error] , results )\n\n* error `mixed` the current error status, *Conditional* family `async.Plan` **DO NOT** pass this argument\n* results `Array` of `mixed` for *Do* family `async.Plan` or just `mixed` for *Conditional* family `async.Plan`, this is **NOT** \n  the final (i.e. *resolved*) results: jobs that finish after the 'resolved' event will have their results listed too, so this\n  can be different from what we get from the 'resolved' event.\n\nThe 'finish' event is fired after the 'resolved' event, when all remaining running jobs are finished.\nIn series flow, there is practically no differences with the 'resolved' event.\nHowever, in a parallel flow, many jobs are running at the same time, if one job finish with an error, the final result is settled right now,\nso the 'resolved' event is fired, however all other pending jobs have to be done for the 'finish' event to be fired.\nAlternatively, when using [`async.race`](#ref.async.race), the first non-error job to finish settle the final result and fire\nthe 'resolved' event, so the 'finish' event is fired when all racing jobs are done.\n\nMost of time, this event is not so useful, however there are cases where we do not want to continue until nothing run in the\nbackground anymore.\n\nWhen in concurrency with others, the 'finish' event is always fired after any others events.\n                        \n\n\n<a name=\"ref.async.JobContext\"></a>\n## Class async.JobContext\n\nJob's function, *using* function and *iterator* function automatically get an async.JobContext instance as its *this* context.\nWe can use this object to perform some particular task.\n\n\n\n<a name=\"ref.async.JobContext.execContext\"></a>\n### .execContext\n\nThis immutable property directly point to the current [`async.ExecContext`](#ref.async.ExecContext)'s instance.\nSo you can use it to listen to event directly from within the job, for example.\n\n\n\n<a name=\"ref.async.JobContext.abort\"></a>\n### .abort( [error] , [arg1] , [arg2], [...] )\n\n* error: any truthy value will be considered as an error\n* arg1, arg2, [...]: job's results\n\nCalling `this.abort()` from inside a job immediately aborts the current job's queue, and triggers completion callbacks.\n\nArguments passed works the same way than regular `callback( [error] , [arg1] , [arg2], [...] )`.\n\nIn fact, in most cases, this is the same than `callback( new Error( 'Error!' ) , arg1, arg2, [...] )` except that it will\nabort the job's queue even when a regular error wouldn't.\nThat's it, even if the `async.Plan` as been created with `.fatal( false )`, or we have set `.retry()`, or even if the\n*error* parameter is falsy, it will abort anyway.\n\nThis can be useful if a job succeed, but require that nothing else should be run afterward.\n\n**Notice:** An async while loop will **\\*NOT\\*** be aborted: **\\*ONLY\\*** the current loop iteration will be aborted,\nthe *whileAction* will be called immediately to evaluate if it should loop again or not.\n\n**Notice:** It has no effect on *Conditional* family `async.Plan`.\n\n\n\n<a name=\"ref.async.JobContext.event.timeout\"></a>\n### Event: 'timeout' ()\n\nThis event is triggered if the current job has been timed out by the underlying lib.\nThis can happen when using the [`.timeout()`](#ref.async.Plan.timeout) method of an `async.Plan` instance.\n\n\n\n## Misc utilities\n\n<a name=\"ref.async.exit\"></a>\n### async.exit( code , timeout )\n\n* code `number` the exit code\n* timeout `number` the maximum time allowed for each underlying listener before aborting, default to 1000 (ms).\n\nThis is a replacement for `process.exit()`, that is **async-friendly**.\n\nWhen `process.exit()` is called, the 'exit' event is emited on the `process` object, and each listener can perform a last\nsynchronous task before the whole process exit. Sadly, a lot of things in Node.js are working asynchronously, and thus cannot\nbe handled properly that way.\n\n**But thanks to `async.exit()` those old days are gone!**\n\nWhen you call `async.exit()`, it emits the 'asyncExit' event on the `process` object.\n\nThere are two kinds of listeners:\n\n* `function( [code] , [timeout] )` listeners, that does not have a callback, are interested in the event but they don't need\n\tto perform critical tasks or they can handle critical tasks synchronously. E.g.: a server that will not accept connection\n\tor data anymore after receiving this event.\n\n* `function( code , timeout , completionCallback )` listeners, that do have a callback, have some critical async tasks to perform\n\tbefore exiting. E.g.: a server that needs to gracefully exit will not accept connection or data anymore, but it still\n\thas to finish client request still in progress.\n\nNote that *code* and *timeout* arguments passed to listeners are actual values processed by `async.exit()`.\n\nSo `async.exit()` will simply wait for all listeners having a *completionCallback* to trigger it (or being timed out) before exiting.\n\nExample:\n\n```js\nprocess.on( 'asyncExit' , function( code , timeout , callback ) {\n\t\n\tconsole.log( 'asyncExit event received - starting a short task' ) ;\n\t\n\tsetTimeout( function() {\n\t\tconsole.log( 'Short task finished' ) ;\n\t\tcallback() ;\n\t} , 100 ) ;\n} ) ;\n\nprocess.on( 'asyncExit' , function( code , timeout ) {\n\t\n\tconsole.log( 'asyncExit event received - non-critical task' ) ;\n\t\n\tsetTimeout( function() {\n\t\tconsole.log( 'Non-critical task finished' ) ;\n\t} , 200 ) ;\n} ) ;\n\nasync.exit( 5 , 500 ) ;\n```\n\nAfter 100ms, it will produce:\n\n```\nasyncExit event received - starting a short task\nasyncExit event received - non-critical task\nShort task finished\n```\n\nNote how the `setTimeout`'s function is not executed in the second event handler: this handler does not accept a callback,\nhence the process will exit as soon as the first handler is done: after 100ms.\n\n\n\n<a name=\"ref.async.setSafeTimeout\"></a>\n### async.setSafeTimeout( fn , timeout )\n\n* fn `function` the function to execute after the timeout\n* timeout `number` the time before running the function\n\nIt returns an opaque value representing the timer.\n\nThis is almost the same than `setTimeout()`.\nThis is great for true timeout function, like this:\n\n```\nfunction fn( callback_ )\n{\n\tvar called = false ;\n\t\n\tvar callback = function() {\n\t\tif ( called ) { return ; }\n\t\tcalled = true ;\n\t\tcallback.apply( this , arguments ) ;\n\t}\n\t\n\tdoSomethingAsync( callback ) ;\n\tasync.setSafeTimeout( callback.bind( new Error( 'Time out!' , 100 ) ) ) ;\n}\n```\n\nWhat if CPU-bound/synchronous task should be done after calling `fn()`, e.g. loading synchronously a lot of configuration files?\nIf performing those tasks takes more than 100ms, a regular `setTimeout()` would trigger the callback after 100ms whatever happened,\nbut *instead* `async.setSafeTimeout()` try to give to `doSomethingAsync()` 100ms to perform its duty.\nIn other words: the timeout start after the event loop take the control back.\nIt also try to not timeout something that has finished its job, but has its callback queued after the timeout callback.\n\n\n\n<a name=\"ref.async.clearSafeTimeout\"></a>\n### async.clearSafeTimeout( timer )\n\n* timer: an opaque value representing a timer\n\nLike `clearTimeout()` but for timer created using `async.setSafeTimeout()`.\nNote that it can clear `setTimeout()` timers too.\n\n\n\n\n\n# BDD Spec\n\nThe Mocha framework is used for BDD-style tests.\n\nThe Full BDD spec generated by Mocha can found [here](https://github.com/cronvel/async-kit/blob/master/bdd-spec.md).\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/cronvel/async-kit.git"
  },
  "scripts": {
    "test": "mocha -R dot"
  },
  "version": "2.2.3"
}
